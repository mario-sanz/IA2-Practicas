{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jpd0gkGnpzXT"
   },
   "source": [
    "# Práctica 2: Procesamiento del Lenguaje Natural\n",
    "\n",
    "__Fecha de entrega: 17 de abril de 2022__\n",
    "\n",
    "El objetivo de esta práctica es aplicar los conceptos teóricos vistos en clase en el módulo de PLN. La práctica consta de 2 notebooks que se entregarán simultáneamente en la tarea de entrega habilitada en el Campus  Virtual.\n",
    "\n",
    "Lo más importante en esta práctica no es el código Python, sino el análisis de los datos y modelos que construyas y las explicaciones razonadas de cada una de las decisiones que tomes. __No se valorarán trozos de código o gráficas sin ningún tipo de contexto o explicación__.\n",
    "\n",
    "Finalmente, recuerda establecer el parámetro `random_state` en todas las funciones que tomen decisiones aleatorias para que los resultados sean reproducibles (los resultados no varíen entre ejecuciones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IBx1oG6bpzXY"
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkJPtLPRpzXa"
   },
   "source": [
    "# Apartado 2: Recuperación de información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWQ9sB-ApzXc"
   },
   "source": [
    "__Número de grupo: 15__\n",
    "\n",
    "__Nombres de los estudiantes: Javier Sande Ríos y Mario Sanz Guerrero__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1iFIS_EpzXc"
   },
   "source": [
    "## 1) Carga del conjunto de datos\n",
    "\n",
    "El fichero `BBC News.csv` contiene noticias clasificadas en 5 categorías diferentes. \n",
    "\n",
    "Carga los datos en un dataframe teniendo en cuenta que la columna `ArticleId` es un identificador de la noticia y por lo tanto no lo vamos a usar. \n",
    "\n",
    "Estudia el tamaño del conjunto de datos y la proporción de noticias que pertenecen a cada una de las categorías.\n",
    "\n",
    "Crea una partición estratificada de los datos dejando el 80% para entrenamiento y el 20% restante para test usando la función `train_test_split` de sklearn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ufbBvGcnpzXe"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>857</td>\n",
       "      <td>double eviction from big brother model caprice...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>325</td>\n",
       "      <td>dj double act revamp chart show dj duo jk and ...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>1590</td>\n",
       "      <td>weak dollar hits reuters revenues at media gro...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>1587</td>\n",
       "      <td>apple ipod family expands market apple has exp...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>538</td>\n",
       "      <td>santy worm makes unwelcome visit thousands of ...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1490 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ArticleId                                               Text  \\\n",
       "0          1833  worldcom ex-boss launches defence lawyers defe...   \n",
       "1           154  german business confidence slides german busin...   \n",
       "2          1101  bbc poll indicates economic gloom citizens in ...   \n",
       "3          1976  lifestyle  governs mobile choice  faster  bett...   \n",
       "4           917  enron bosses in $168m payout eighteen former e...   \n",
       "...         ...                                                ...   \n",
       "1485        857  double eviction from big brother model caprice...   \n",
       "1486        325  dj double act revamp chart show dj duo jk and ...   \n",
       "1487       1590  weak dollar hits reuters revenues at media gro...   \n",
       "1488       1587  apple ipod family expands market apple has exp...   \n",
       "1489        538  santy worm makes unwelcome visit thousands of ...   \n",
       "\n",
       "           Category  \n",
       "0          business  \n",
       "1          business  \n",
       "2          business  \n",
       "3              tech  \n",
       "4          business  \n",
       "...             ...  \n",
       "1485  entertainment  \n",
       "1486  entertainment  \n",
       "1487       business  \n",
       "1488           tech  \n",
       "1489           tech  \n",
       "\n",
       "[1490 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('BBC News.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport            346\n",
       "business         336\n",
       "politics         274\n",
       "entertainment    273\n",
       "tech             261\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD4CAYAAAAdIcpQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAYF0lEQVR4nO3df7SdVX3n8ffXgMjkMokUe1cENCyN4yBZUrkLcWxn7pWqEVcHnKLFMkqUrugMVp1GF7HTqTiV1fgD6YgWjYOTqNQrojYY0JFGU0RFTCTkBqiaQmjN0KQaCKKUNvCdP54dOVxuss89555zcsn7tdZZ9zn7efZ59t53n/O5z3Oec25kJpIkHciTBt0ASdLBz7CQJFUZFpKkKsNCklRlWEiSqg4bdAMAjjnmmFy4cGFHdX/+858zd+7cmW3QE5xjNj2O1/Q4XtPTzXht2rTpJ5n5tBlu0pQOirBYuHAhGzdu7Kjuhg0bGB0dndkGPcE5ZtPjeE2P4zU93YxXRNw9s63ZP09DSZKqDAtJUpVhIUmqqoZFRDwlIm6OiFsj4raIeE8pXx0Rd0XE5nI7uZRHRHw4IrZFxJaIeEGP+yBJ6rF23uB+CHhJZj4QEYcDN0bEV8q6d2bm1ZO2fwWwqNxeCFxefkqSZqnqkUU2Hih3Dy+3A3374JnAp0q9m4D5EbGg+6ZKkgYl2vnW2YiYA2wCng18NDMvjIjVwItojjzWAysy86GIWAeszMwbS931wIWZuXHSYy4DlgEMDw+fMj4+3lEHHnjgAYaGhjqqe6hyzKbH8Zoex2t6uhmvsbGxTZk5MsNNmlJbn7PIzIeBkyNiPvCliDgJeBfwD8CTgVXAhcD/bHfHmbmq1GNkZCQ7vc7Ya7qnzzGbHsdrehyv6Zkt4zWtq6Ey8z7gG8CSzLynnGp6CPg/wKllsx3A8S3VjitlkqRZqnpkERFPA/4lM++LiCOBlwLvi4gFmXlPRARwFrC1VLkGeEtEjNO8sb0nM+/pTfMlzbSFK67tqv7yxXtZ2uFjbF/5yq72rd5p5zTUAmBNed/iScBVmbkuIr5egiSAzcCby/bXAWcA24BfAG+Y8VZLkvqqGhaZuQX4tSnKX7Kf7RO4oPumSZIOFn6CW5JUZVhIkqoMC0lS1UHx/yy6MbFjT8dXXnTLKzckHSo8spAkVRkWkqQqw0KSVGVYSJKqDAtJUpVhIUmqMiwkSVWGhSSpyrCQJFUZFpKkKsNCklRlWEiSqgwLSVKVYSFJqjIsJElVhoUkqcqwkCRVVcMiIp4SETdHxK0RcVtEvKeUnxAR342IbRHxuYh4cik/otzfVtYv7HEfJEk91s6RxUPASzLz+cDJwJKIOA14H3BpZj4buBc4v2x/PnBvKb+0bCdJmsWqYZGNB8rdw8stgZcAV5fyNcBZZfnMcp+y/vSIiJlqsCSp/yIz6xtFzAE2Ac8GPgp8ALipHD0QEccDX8nMkyJiK7AkM39c1v0t8MLM/Mmkx1wGLAMYHh4+ZXx8vKMO7Nq9h50PdlS1a4uPnTeYHXfpgQceYGhoaNDNmDUOtfGa2LGnq/rDR9Lxc3K2Pqe60c38Ghsb25SZIzPcpCkd1s5GmfkwcHJEzAe+BDy32x1n5ipgFcDIyEiOjo529DiXXbmWSyba6saM237u6ED2260NGzbQ6Xgfig618Vq64tqu6i9fvLfj5+RsfU51Y7bMr2ldDZWZ9wHfAF4EzI+IfTPiOGBHWd4BHA9Q1s8DfjoTjZUkDUY7V0M9rRxREBFHAi8F7qAJjbPLZucBa8vyNeU+Zf3Xs51zXZKkg1Y7x4oLgDXlfYsnAVdl5rqIuB0Yj4j3ArcAV5TtrwA+HRHbgN3AOT1otySpj6phkZlbgF+bovxO4NQpyv8JePWMtE6SdFDwE9ySpCrDQpJUZVhIkqoMC0lSlWEhSaoyLCRJVYaFJKnKsJAkVRkWkqQqw0KSVDWY7/aWZpGJHXu6/truTmxf+cq+7/NQtXAAv999Vi+ZO7B9T4dHFpKkKsNCklRlWEiSqgwLSVKVYSFJqjIsJElVhoUkqcrPWcxC3V4Tvnzx3o4/N+C1/9KhySMLSVKVYSFJqqqGRUQcHxHfiIjbI+K2iHhbKb8oInZExOZyO6OlzrsiYltE/CAiXt7LDkiSeq+d9yz2Assz8/sRcRSwKSKuL+suzcwPtm4cEScC5wDPA54O/FVEPCczH57JhkuS+qd6ZJGZ92Tm98vyz4A7gGMPUOVMYDwzH8rMu4BtwKkz0VhJ0mBEZra/ccRC4AbgJOAPgKXA/cBGmqOPeyPiI8BNmfmZUucK4CuZefWkx1oGLAMYHh4+ZXx8vKMO7Nq9h50PdlS1a4uPnTeQ/U7s2NNV/eEj6XjMBtXnQRrUHHN+9U+3fe7GCfPmMDQ01FHdsbGxTZk5MsNNmlLbl85GxBDwBeDtmXl/RFwO/AmQ5eclwBvbfbzMXAWsAhgZGcnR0dFpNPtRl125lksmBnMF8PZzRwey326/Lnv54r0dj9mg+jxIg5pjzq/+GcRX0O+zeslcOn3966e2roaKiMNpguLKzPwiQGbuzMyHM/MR4BM8eqppB3B8S/XjSpkkaZZq52qoAK4A7sjMD7WUL2jZ7FXA1rJ8DXBORBwREScAi4CbZ67JkqR+a+dY8cXA64CJiNhcyv4QeG1EnExzGmo78CaAzLwtIq4Cbqe5kuoCr4SSpNmtGhaZeSMQU6y67gB1LgYu7qJdkqSDiJ/gliRVGRaSpCrDQpJUZVhIkqoMC0lSlWEhSaoyLCRJVYaFJKnKsJAkVRkWkqQqw0KSVGVYSJKqDAtJUpVhIUmqMiwkSVWGhSSpyrCQJFUZFpKkKsNCklRlWEiSqgwLSVJVNSwi4viI+EZE3B4Rt0XE20r50RFxfUT8qPx8aimPiPhwRGyLiC0R8YJed0KS1FvtHFnsBZZn5onAacAFEXEisAJYn5mLgPXlPsArgEXltgy4fMZbLUnqq2pYZOY9mfn9svwz4A7gWOBMYE3ZbA1wVlk+E/hUNm4C5kfEgpluuCSpfyIz2984YiFwA3AS8HeZOb+UB3BvZs6PiHXAysy8saxbD1yYmRsnPdYymiMPhoeHTxkfH++oA7t272Hngx1V7driY+cNZL8TO/Z0VX/4SDoes0H1eZAGNcecX/3TbZ+7ccK8OQwNDXVUd2xsbFNmjsxwk6Z0WLsbRsQQ8AXg7Zl5f5MPjczMiGg/dZo6q4BVACMjIzk6Ojqd6r902ZVruWSi7W7MqO3njg5kv0tXXNtV/eWL93Y8ZoPq8yANao45v/qn2z53Y/WSuXT6+tdPbV0NFRGH0wTFlZn5xVK8c9/ppfJzVynfARzfUv24UiZJmqXauRoqgCuAOzLzQy2rrgHOK8vnAWtbyl9froo6DdiTmffMYJslSX3WzrHii4HXARMRsbmU/SGwErgqIs4H7gZeU9ZdB5wBbAN+AbxhJhssSeq/aliUN6pjP6tPn2L7BC7osl2SpIOIn+CWJFUZFpKkKsNCklRlWEiSqgwLSVKVYSFJqjIsJElVhoUkqcqwkCRVGRaSpCrDQpJUZVhIkqoMC0lSlWEhSaoyLCRJVYaFJKnKsJAkVRkWkqQqw0KSVGVYSJKqDAtJUlU1LCLikxGxKyK2tpRdFBE7ImJzuZ3Rsu5dEbEtIn4QES/vVcMlSf3TzpHFamDJFOWXZubJ5XYdQEScCJwDPK/U+fOImDNTjZUkDUY1LDLzBmB3m493JjCemQ9l5l3ANuDULtonSToIRGbWN4pYCKzLzJPK/YuApcD9wEZgeWbeGxEfAW7KzM+U7a4AvpKZV0/xmMuAZQDDw8OnjI+Pd9SBXbv3sPPBjqp2bfGx8way34kde7qqP3wkHY/ZoPo8SIOaY86v/um2z904Yd4choaGOqo7Nja2KTNHZrhJUzqsw3qXA38CZPl5CfDG6TxAZq4CVgGMjIzk6OhoRw257Mq1XDLRaTe6s/3c0YHsd+mKa7uqv3zx3o7HbFB9HqRBzTHnV/902+durF4yl05f//qpo6uhMnNnZj6cmY8An+DRU007gONbNj2ulEmSZrGOwiIiFrTcfRWw70qpa4BzIuKIiDgBWATc3F0TJUmDVj1WjIjPAqPAMRHxY+DdwGhEnExzGmo78CaAzLwtIq4Cbgf2Ahdk5sM9abkkqW+qYZGZr52i+IoDbH8xcHE3jZIkHVz8BLckqcqwkCRVGRaSpCrDQpJUZVhIkqoMC0lSlWEhSaoyLCRJVYaFJKnKsJAkVRkWkqQqw0KSVGVYSJKqDAtJUpVhIUmqMiwkSVWGhSSpyrCQJFUZFpKkKsNCklRlWEiSqqphERGfjIhdEbG1pezoiLg+In5Ufj61lEdEfDgitkXEloh4QS8bL0nqj3aOLFYDSyaVrQDWZ+YiYH25D/AKYFG5LQMun5lmSpIGqRoWmXkDsHtS8ZnAmrK8BjirpfxT2bgJmB8RC2aorZKkAYnMrG8UsRBYl5knlfv3Zeb8shzAvZk5PyLWASsz88aybj1wYWZunOIxl9EcfTA8PHzK+Ph4Rx3YtXsPOx/sqGrXFh87byD7ndixp6v6w0fS8ZgNqs+DNKg55vzqn2773I0T5s1haGioo7pjY2ObMnNkhps0pcO6fYDMzIioJ87j660CVgGMjIzk6OhoR/u/7Mq1XDLRdTc6sv3c0YHsd+mKa7uqv3zx3o7HbFB9HqRBzTHnV/902+durF4yl05f//qp06uhdu47vVR+7irlO4DjW7Y7rpRJkmaxTsPiGuC8snwesLal/PXlqqjTgD2ZeU+XbZQkDVj1WDEiPguMAsdExI+BdwMrgasi4nzgbuA1ZfPrgDOAbcAvgDf0oM2SpD6rhkVmvnY/q06fYtsELui2UZKkg4uf4JYkVRkWkqQqw0KSVGVYSJKqDAtJUpVhIUmqMiwkSVWGhSSpyrCQJFUZFpKkKsNCklRlWEiSqgwLSVKVYSFJqjIsJElVhoUkqcqwkCRVGRaSpCrDQpJUZVhIkqoMC0lS1WHdVI6I7cDPgIeBvZk5EhFHA58DFgLbgddk5r3dNVOSNEgzcWQxlpknZ+ZIub8CWJ+Zi4D15b4kaRbrxWmoM4E1ZXkNcFYP9iFJ6qPIzM4rR9wF3Ask8PHMXBUR92Xm/LI+gHv33Z9UdxmwDGB4ePiU8fHxjtqwa/cedj7YWfu7tfjYeQPZ78SOPV3VHz6SjsdsUH0epEHNMedX/3Tb526cMG8OQ0NDHdUdGxvb1HJWp6e6es8C+PXM3BERvwpcHxF/07oyMzMipkyjzFwFrAIYGRnJ0dHRjhpw2ZVruWSi2250Zvu5owPZ79IV13ZVf/nivR2P2aD6PEiDmmPOr/7pts/dWL1kLp2+/vVTV6ehMnNH+bkL+BJwKrAzIhYAlJ+7um2kJGmwOg6LiJgbEUftWwZeBmwFrgHOK5udB6zttpGSpMHq5th6GPhS87YEhwF/kZlfjYjvAVdFxPnA3cBrum+mJGmQOg6LzLwTeP4U5T8FTu+mUZKkg4uf4JYkVRkWkqQqw0KSVGVYSJKqDAtJUpVhIUmqMiwkSVWGhSSpyrCQJFUZFpKkKsNCklRlWEiSqgwLSVKVYSFJqjIsJElVhoUkqcqwkCRVGRaSpCrDQpJUZVhIkqoMC0lSVc/CIiKWRMQPImJbRKzo1X4kSb3Xk7CIiDnAR4FXACcCr42IE3uxL0lS7/XqyOJUYFtm3pmZ/wyMA2f2aF+SpB6LzJz5B404G1iSmb9X7r8OeGFmvqVlm2XAsnL33wA/6HB3xwA/6aK5hyLHbHocr+lxvKanm/F6ZmY+bSYbsz+H9WMnU8nMVcCqbh8nIjZm5sgMNOmQ4ZhNj+M1PY7X9MyW8erVaagdwPEt948rZZKkWahXYfE9YFFEnBARTwbOAa7p0b4kST3Wk9NQmbk3It4C/F9gDvDJzLytF/tiBk5lHYIcs+lxvKbH8ZqeWTFePXmDW5L0xOInuCVJVYaFJKmqr2EREQsjYmuXj/H0iLh6ptr0RBER8yPiv3ZYd3X5bMwhLyI2RMRIWb6ujOtjxtY52L2IGI2IfzfodrQjIs7q5Bso2u1jRPzHQX0l0nReN2bdkUVm/r/M9IXt8eYDHYWFppaZZ2TmfUwaW+dgdyLiMGAUmBVhAZxF87VFbZtOHzPzmsxc2VHLujefdl83MrNvN2Ah8DfAlcAdwNXAvwK2A8eUbUaADWX5PwCby+0W4KjyGFvL+qXAF4GvAj8C3t+yr5cB3wG+D3weGCrlK4HbgS3AB0vZq4GtwK3ADf0ckxkc23HgwTJWHwDeSXMJ8xbgPS3bvb6U3Qp8upStBj4MfBu4Ezh70P3pw5w7vcypCeCTwBFl+w3ASFneTvPp2slj2zoH5wAfLPNnC/D7+5tns/UGzAWuLXNmK/A7ZWzeX8bvZuDZLeP99dLv9cAzWubYx4DvlufsP9B89moz8BsD6NN/Lu3eDHy8/B4fAC4u/bwJGKZ5sd8N3FW2fVa5fRXYBHwTeG47fQR+q6y7BfgrYLjUWwp8pOUxHvdcpAmevwbWlvKVwLmlDxPAs8p2TwO+QPPc/x7w4lJ+Ec0831Dqv7WUP2ZuH3DMBvDEzZYOfBJ4B/sPiy+3bDtEc6nvQh4bFncC84CnAHfTfBjwGOAGYG7Z7kLgj4FfoflakX1Xgc0vPyeAY1vLZttt0ri8jOZyvKA5elwH/HvgecAPW8b66JYJ+vmy7Yk03+s18D71cM79EfD3wHNK2aeAt5flDTw+LH45tlOM9X+hCaDD9o3p/ubZbL0Bvw18ouX+vDI2/73cfz2wrix/GTivLL8R+MuWObYOmFPuXwS8Y0D9+belnYeX+39e+pDAb5Wy9wN/1NL2s1vqrwcWleUXAl9vp4/AU1vmxO8Bl5TlpTw2LB73XKQJi/uABcARNCH0nrLubcCfleW/AH69LD8DuKOlLd8udY8BfgocPnluH+g2iK/7+PvM/FZZ/gzw1gNs+y3gQxFxJfDFzPxxREzeZn1m7gGIiNuBZ9IcWp0IfKts/2Sao4w9wD8BV0TEOppf7L79rI6Iq2j+IpjtXlZut5T7Q8Ai4PnA5zPzJwCZubulzl9m5iPA7REx3M/G9sHkOfc/gLsy84elbA1wAfBnHTz2bwIfy8y90IxpOQUx1TybrSaASyLifTSh8M3yvPpsWf9Z4NKy/CLgP5XlT9O86O7z+cx8uA/trTkdOAX4XunHkcAu4J959He1CXjp5IoRMURztPH5lteiI1o2OVAfjwM+FxELaF6T7trPdvt7Ln4vM+8p7fhb4GulfAIYK8u/CZzY0rZ/XdoMcG1mPgQ8FBG7aI6c2jaIsJj8wY4E9vLo+ydP+eWKzJURcS1wBs0L/8tpnoStHmpZfpimTwFcn5mvnbzziDiVZrKcDbwFeElmvjkiXgi8EtgUEadk5k877eBBIIA/zcyPP6Yw4vcPUKd1HB+XyLPc5Dl3H81f/73ZWfOh1MfNs17tr9cy84cR8QKa5+F7I2L9vlWtm7XxUD+f8cZ1JoA1mfmuxxRGvCPLn+E8+loy2ZOA+zLz5P089oH6eBnwocy8JiJGaf7an8r+nout5Y+03H+kpa1PAk7LzMe8TpbwmOq1sm2DeIP7GRHxorL8u8CNNIe0p5Sy3963YUQ8KzMnMvN9NOffntvmPm4CXhwRzy6PMzcinlMSdl5mXgf8N5q/tPft57uZ+cfAP/LY77WaLX5G854ONJ+cf+O+vygi4tiI+FWac8mvjohfKeVHD6Sl/Td5zm0EFu6bH8DraM4H70/r2E52PfCmcjRBRBy9v3k2W0XE04FfZOZnaN6zeUFZ9TstP79Tlr9N8/U+0JxT/+Z+HvZAY9pr64Gzy3Ni3+/smQfY/pdtzcz7gbsi4tWlbkTE/n6/k/s4j0e/I++8Ltp/IF8DfvlHYUScXNm+7d/DIMLiB8AFEXEHzTm8y4H3AP8rIjbSJN4+b4+IrRGxBfgX4Cvt7CAz/5HmPOBnS93v0ATNUcC6UnYj8AelygciYqJc1vttmje4ZpVyJPSt0oeX0py7/E5ETNCcUz8qm69cuRj464i4FfjQwBrcX5Pn3KXAG2hOJUzQ/GX2sf1Vbh3biPjApNX/G/g7YEsZ099l//NstloM3BwRm4F3A+8t5U8tfXwbTShC80L1hlL+urJuKl8GXhURmyPiN3rW8ilk5u0071t9rbTzepr3AvZnHHhnRNwSEc+iCcHzy+/7Nvb/v3om9/Eimjm3id59hftbgZGI2FJOy7/5QBtX5vZj+HUfekKLiIU059lPGnRbnkgiYjvNhQD+34pDxKz7nIUkqf88spAkVXlkIUmqMiwkSVWGhSSpyrCQJFUZFpKkqv8PPbz6RS6+dJ0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Category'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver al hacer la funcion value_counts() y al ver el histograma, la cantidad de noticias pertenecientes a cada categoría varía bastante, pero no lo suficiente como para suponer un problema a la hora de clasificar las noticias según su categoría porque tenemos una cantidad suficiente de cada una.\n",
    "\n",
    "A continuación vamos a crear las particiones de los datos, a las que le daremos un 80% de los datos para entrenamiento y el 20% restante para test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "news = df['Text'].to_numpy()\n",
    "categories = df['Category'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(news,\n",
    "                                                    categories,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = RANDOM_STATE,\n",
    "                                                    shuffle = True,\n",
    "                                                    stratify = categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Fx5hJC7pzXf"
   },
   "source": [
    "## 2) Representación basada en bolsa de palabras y tf-idf\n",
    "\n",
    "La primera vectorización que vamos a usar representará los mensajes usando el modelo de bolsa de palabras, monogramas y el valor tf-idf de cada palabra. Usa como _stop words_ las que vienen configuradas por defecto para el inglés.\n",
    "\n",
    "Aplica la vectorización a los conjuntos de mensajes de entrenamiento y test. Muestra algún mensaje tanto en su formato de texto original como en la versión vectorizada. ¿Qué palabras se han eliminado y por qué?\n",
    "\n",
    "Calcula la precisión@5 de cada una de las clases usando como consultas los documentos de la partición de test y la similitud del coseno. Vamos a considerar que un documento recuperado es relevante cuando pertenezca a la misma clase que la consulta.\n",
    "\n",
    "Dibuja los resultados en un diagrama de barras y comenta las clases en las que se comporta mejor y peor. ¿Crees que los resultados son buenos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wKdL2-VSpzXg"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words = 'english',\n",
    "                             binary = False, # frecuencia de aparición (NO simplemente si aparece o no)\n",
    "                             ngram_range=(1,1), # solo monogramas\n",
    "                             token_pattern=r'(?u)\\b[A-Za-z]+\\b') # solo palabras que tengan letras\n",
    "\n",
    "train_vector_data = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "\n",
    "tfidftrans = TfidfTransformer()\n",
    "train_preprocessed = tfidftrans.fit_transform(train_vector_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "def write_terms (feature_names, data, vector_data, index):\n",
    "    '''\n",
    "    Escribe los términos presentes en un mensaje representado como bolsa de palabras.\n",
    "    \n",
    "    - feature_names: terminos usados para vectorizar\n",
    "    - data: lista de mensajes original (si data==None no se muestra el mensaje original)\n",
    "    - vector_data: matriz (dispersa) de mensaje vectorizados\n",
    "    - index: posición del mensaje a mostrar\n",
    "    '''\n",
    "    # máscara para seleccionar sólo el mensaje en posición index\n",
    "    mask=vector_data[index,:]>0\n",
    "    \n",
    "    # términos que aparecen en ese mensaje vectorizado\n",
    "    terminos = ma.array(feature_names, mask = ~(mask[0].toarray()))\n",
    "    \n",
    "    # mostrar mensaje original\n",
    "    if data is not None:\n",
    "        print('Mensaje', index, 'SIN vectorizar:', data[index], '\\n')\n",
    "    \n",
    "    # mostrar términos que aparecen en el mensaje vectorizado\n",
    "    print('Mensaje', index, 'vectorizado:', terminos.compressed(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mensaje 10 SIN vectorizar: blair ready to call election tony blair seems certain to end weeks of phoney war on monday and announce there will be a general election on 5 may.  the date has been pencilled into the diaries of politicians and political journalists for many months and  despite occasional panics that the prime minister was on the verge of calling a snap poll  it has not shifted. over the weeks  there have been any number of signs that 050505 was going to be the day mr blair would go for an historic third term. and the calling of a special political cabinet meeting has only added to the belief that the announcement is imminent. the prime minister and his campaign boss alan milburn have already insisted the election will be fought on the economy and what they claim is a stark choice between labour s stability and investment against tory cuts and boom and bust.  and chancellor gordon brown has stepped into the front line of the campaign - to the relief of many of his supporters in westminster - to underline that economic message. and it is certain one of the big arguments at the centre of the election battle will be around the big parties  tax and spend policies.  during the phoney campaign  labour got into trouble over its central claim that michael howard was planning £35 bn cuts in public services. the prime minister found himself struggling to explain how a smaller  slower increase in spending planned by the tories compared to labour s plans was a cut. and it looked like the labour campaign - which was already being criticised for being thrown into defensive mode by mr howard on issues such as immigration and health - was on the rocks. then deputy conservative chairman howard flight was reported to have suggested mr howard was secretly planning even bigger  cuts .  he was sacked for his gaffe  but the damage had been done and the faltering labour campaign was back on track. a second central argument will be over taxation  with the tories claiming the chancellor has to fill a black hole at the centre of his finances and will be forced to raise taxes if labour wins again. mr brown slaps that aside  claiming his forecasts are accurate and that previous claims of looming economic disaster have proved inaccurate. as usual  the liberal democrats will have to fight to get their voice heard over the sounds of battle between the two big parties. but leader charles kennedy believes he has set out a distinctive manifesto with plans for a tax rise for the wealthiest to finance extra spending and the abolition of the council tax in favour of a local income tax. other issues are certain to play a part - immigration and asylum  the war on iraq  law and order and education  for example. but  as ever  it will be the economy that will almost certainly decide the outcome. and  whatever that outcome  2005 is set to be a far more lively  even bitter campaign than 2001 s non-event. \n",
      "\n",
      "Mensaje 10 vectorizado: ['abolition' 'accurate' 'added' 'alan' 'announce' 'announcement'\n",
      " 'argument' 'arguments' 'aside' 'asylum' 'battle' 'belief' 'believes'\n",
      " 'big' 'bigger' 'bitter' 'black' 'blair' 'bn' 'boom' 'boss' 'brown' 'bust'\n",
      " 'cabinet' 'calling' 'campaign' 'central' 'centre' 'certain' 'certainly'\n",
      " 'chairman' 'chancellor' 'charles' 'choice' 'claim' 'claiming' 'claims'\n",
      " 'compared' 'conservative' 'council' 'criticised' 'cut' 'cuts' 'damage'\n",
      " 'date' 'day' 'decide' 'defensive' 'democrats' 'deputy' 'despite'\n",
      " 'diaries' 'disaster' 'distinctive' 'economic' 'economy' 'education'\n",
      " 'election' 'end' 'event' 'example' 'explain' 'extra' 'faltering' 'far'\n",
      " 'favour' 'fight' 'finance' 'finances' 'flight' 'forced' 'forecasts'\n",
      " 'fought' 'gaffe' 'general' 'going' 'gordon' 'got' 'health' 'heard'\n",
      " 'historic' 'hole' 'howard' 'immigration' 'imminent' 'inaccurate' 'income'\n",
      " 'increase' 'insisted' 'investment' 'iraq' 'issues' 'journalists'\n",
      " 'kennedy' 'labour' 'law' 'leader' 'liberal' 'like' 'line' 'lively'\n",
      " 'local' 'looked' 'looming' 'manifesto' 'meeting' 'message' 'michael'\n",
      " 'milburn' 'minister' 'mode' 'monday' 'months' 'mr' 'non' 'number'\n",
      " 'occasional' 'order' 'outcome' 'panics' 'parties' 'pencilled' 'phoney'\n",
      " 'planned' 'planning' 'plans' 'play' 'policies' 'political' 'politicians'\n",
      " 'poll' 'previous' 'prime' 'proved' 'public' 'raise' 'ready' 'relief'\n",
      " 'reported' 'rise' 'rocks' 's' 'sacked' 'second' 'secretly' 'services'\n",
      " 'set' 'shifted' 'signs' 'slaps' 'slower' 'smaller' 'snap' 'sounds'\n",
      " 'special' 'spend' 'spending' 'stability' 'stark' 'stepped' 'struggling'\n",
      " 'suggested' 'supporters' 'tax' 'taxation' 'taxes' 'term' 'thrown' 'tony'\n",
      " 'tories' 'tory' 'track' 'trouble' 'underline' 'usual' 'verge' 'voice'\n",
      " 'war' 'wealthiest' 'weeks' 'westminster' 'wins'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "write_terms(feature_names, X_train, train_preprocessed, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, el mensaje vectorizado es un conjunto de todas las palabras que contiene el mensaje. Al ser un conjunto, cada palabra aparece una sola vez, pero internamente tiene almacenada la frecuencia de aparición de cada palabra, ya que así se lo hemos pedido al poner la variable `binary = False` en la inicialización de `vectorizer`.\n",
    "\n",
    "Para estudiar las palabras eliminadas al aplicar la vectorización vamos a hacer una función similar a la anterior. Esta función (`palabras_eliminadas`) va a iterar por cada palabra del texto original y la buscará en el conjunto del mensaje vectorizado. En caso de que el conjunto no incluya esta palabra, será porque se ha eliminado. Estas palabras serán impresas por la función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def palabras_eliminadas (feature_names, data, vector_data, index):\n",
    "    # máscara para seleccionar sólo el mensaje en posición index\n",
    "    mask=vector_data[index,:]>0\n",
    "    \n",
    "    # términos que aparecen en ese mensaje vectorizado\n",
    "    terminos = ma.array(feature_names, mask = ~(mask[0].toarray()))\n",
    "    conjunto = terminos.compressed()\n",
    "    \n",
    "    # mensaje original\n",
    "    for palabra in data[index].split():\n",
    "        if palabra not in conjunto:\n",
    "            print(palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to\n",
      "call\n",
      "seems\n",
      "to\n",
      "of\n",
      "on\n",
      "and\n",
      "there\n",
      "will\n",
      "be\n",
      "a\n",
      "on\n",
      "5\n",
      "may.\n",
      "the\n",
      "has\n",
      "been\n",
      "into\n",
      "the\n",
      "of\n",
      "and\n",
      "for\n",
      "many\n",
      "and\n",
      "that\n",
      "the\n",
      "was\n",
      "on\n",
      "the\n",
      "of\n",
      "a\n",
      "it\n",
      "has\n",
      "not\n",
      "shifted.\n",
      "over\n",
      "the\n",
      "there\n",
      "have\n",
      "been\n",
      "any\n",
      "of\n",
      "that\n",
      "050505\n",
      "was\n",
      "to\n",
      "be\n",
      "the\n",
      "would\n",
      "go\n",
      "for\n",
      "an\n",
      "third\n",
      "term.\n",
      "and\n",
      "the\n",
      "of\n",
      "a\n",
      "has\n",
      "only\n",
      "to\n",
      "the\n",
      "that\n",
      "the\n",
      "is\n",
      "imminent.\n",
      "the\n",
      "and\n",
      "his\n",
      "have\n",
      "already\n",
      "the\n",
      "will\n",
      "be\n",
      "on\n",
      "the\n",
      "and\n",
      "what\n",
      "they\n",
      "is\n",
      "a\n",
      "between\n",
      "and\n",
      "against\n",
      "and\n",
      "and\n",
      "bust.\n",
      "and\n",
      "has\n",
      "into\n",
      "the\n",
      "front\n",
      "of\n",
      "the\n",
      "-\n",
      "to\n",
      "the\n",
      "of\n",
      "many\n",
      "of\n",
      "his\n",
      "in\n",
      "-\n",
      "to\n",
      "that\n",
      "message.\n",
      "and\n",
      "it\n",
      "is\n",
      "one\n",
      "of\n",
      "the\n",
      "at\n",
      "the\n",
      "of\n",
      "the\n",
      "will\n",
      "be\n",
      "around\n",
      "the\n",
      "and\n",
      "policies.\n",
      "during\n",
      "the\n",
      "into\n",
      "over\n",
      "its\n",
      "that\n",
      "was\n",
      "£35\n",
      "in\n",
      "services.\n",
      "the\n",
      "found\n",
      "himself\n",
      "to\n",
      "how\n",
      "a\n",
      "in\n",
      "by\n",
      "the\n",
      "to\n",
      "was\n",
      "a\n",
      "cut.\n",
      "and\n",
      "it\n",
      "the\n",
      "-\n",
      "which\n",
      "was\n",
      "already\n",
      "being\n",
      "for\n",
      "being\n",
      "into\n",
      "by\n",
      "on\n",
      "such\n",
      "as\n",
      "and\n",
      "-\n",
      "was\n",
      "on\n",
      "the\n",
      "rocks.\n",
      "then\n",
      "was\n",
      "to\n",
      "have\n",
      "was\n",
      "even\n",
      ".\n",
      "he\n",
      "was\n",
      "for\n",
      "his\n",
      "but\n",
      "the\n",
      "had\n",
      "been\n",
      "done\n",
      "and\n",
      "the\n",
      "was\n",
      "back\n",
      "on\n",
      "track.\n",
      "a\n",
      "will\n",
      "be\n",
      "over\n",
      "with\n",
      "the\n",
      "the\n",
      "has\n",
      "to\n",
      "fill\n",
      "a\n",
      "at\n",
      "the\n",
      "of\n",
      "his\n",
      "and\n",
      "will\n",
      "be\n",
      "to\n",
      "if\n",
      "again.\n",
      "that\n",
      "his\n",
      "are\n",
      "and\n",
      "that\n",
      "of\n",
      "have\n",
      "inaccurate.\n",
      "as\n",
      "the\n",
      "will\n",
      "have\n",
      "to\n",
      "to\n",
      "get\n",
      "their\n",
      "over\n",
      "the\n",
      "of\n",
      "between\n",
      "the\n",
      "two\n",
      "parties.\n",
      "but\n",
      "he\n",
      "has\n",
      "out\n",
      "a\n",
      "with\n",
      "for\n",
      "a\n",
      "for\n",
      "the\n",
      "to\n",
      "and\n",
      "the\n",
      "of\n",
      "the\n",
      "in\n",
      "of\n",
      "a\n",
      "tax.\n",
      "other\n",
      "are\n",
      "to\n",
      "a\n",
      "part\n",
      "-\n",
      "and\n",
      "the\n",
      "on\n",
      "and\n",
      "and\n",
      "for\n",
      "example.\n",
      "but\n",
      "as\n",
      "ever\n",
      "it\n",
      "will\n",
      "be\n",
      "the\n",
      "that\n",
      "will\n",
      "almost\n",
      "the\n",
      "outcome.\n",
      "and\n",
      "whatever\n",
      "that\n",
      "2005\n",
      "is\n",
      "to\n",
      "be\n",
      "a\n",
      "more\n",
      "even\n",
      "than\n",
      "2001\n",
      "non-event.\n"
     ]
    }
   ],
   "source": [
    "palabras_eliminadas(feature_names, X_train, train_vector_data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si analizamos las palabras que han sido eliminadas, todas ellas son palabras en inglés que se repiten mucho y que no aportan conocimiento al mensaje. Simplemente aportan corrección sintáctica, pero son palabras vacías, lo que conocemos como **stop words**. Si revisamos la inicialización de `vectorizer`, vemos que le habíamos pedido que quitara las stop words del inglés, así que es correcto que estas palabras no hayan sido incluidas en la vectorización.\n",
    "\n",
    "Vamos a hacer lo mismo pero para el conjunto de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANTE: Para el conjunto de test no hace falta el \"fit\", ya que vamos a usar solo las palabras\n",
    "# encontradas en el conjunto de entrenamiento, por lo que haremos solo \"transform\"\n",
    "test_vector_data = vectorizer.transform(X_test)\n",
    "# Calculamos también su valor TF-IDF (el IDF es el del conjunto de entrenamiento)\n",
    "test_preprocessed = tfidftrans.transform(test_vector_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una serie de funciones para calcular la precisión@5 de cada una de las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def knn(query, X_train, k):\n",
    "    '''Devuelve los índices de los k documentos de entrenamiento más similares a la consulta usando \n",
    "    la similitud del coseno.\n",
    "    \n",
    "    Parámetros:\n",
    "    - query: documento consulta vectorizado\n",
    "    - X_train: documentos de entrenamiento vectorizados\n",
    "    - k: número de documentos a recuperar\n",
    "    \n",
    "    Devuelve:\n",
    "    - índices de los k documentos más similares a la consulta.\n",
    "    '''\n",
    "    \n",
    "    # Necesitamos un vector de dimensión (1, X). Si se pasa un vector de dimensión X, transformarlo\n",
    "    if len(query.shape) == 1:\n",
    "        query = query.reshape(1, -1)\n",
    "\n",
    "    simil = cosine_similarity(query, X_train)\n",
    "    simil_idx = np.argsort(simil.flatten())\n",
    "    simil_idx = simil_idx[::-1]\n",
    "    return simil_idx[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(y_selected, y_real, k):\n",
    "    '''Devuelve la precisión @k de los documentos seleccionados.\n",
    "    \n",
    "    Parametros:\n",
    "    - y_selected: etiquetas de los documentos seleccionados (se usan los k primeros)\n",
    "    - y_real: etiqueta de la categoría correcta\n",
    "    - k: número de documentos que se tienen en cuenta\n",
    "    \n",
    "    Devuelve:\n",
    "    - Precisión@k\n",
    "    '''\n",
    "    \n",
    "    return np.sum(y_selected[:k] == y_real) / k * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_precisions_per_class(X_train, y_train, X_test, y_test, k):\n",
    "    '''Devuelve las precision@k media para cada una de las classes.\n",
    "    \n",
    "    Parámetros:\n",
    "    - X_train: documentos de entrenamiento vectorizados.\n",
    "    - y_train: etiquetas de los documentos de entrenamiento.\n",
    "    - X_test: documentos vectorizados que se usan como consultas\n",
    "    - y_test: etiquetas de los documentos que se usan como consultas\n",
    "    - k: número de documentos considerados a recuperar por la consulta\n",
    "    \n",
    "    Devuelve:\n",
    "    - Diccionario clase -> precisión en tanto por ciento.\n",
    "    '''\n",
    "    \n",
    "    # diccionario categoría -> lista de precisiones\n",
    "    y_precisions = {y: [] for y in np.unique(y_test)}\n",
    "    \n",
    "    # Calcular precision@k para cada consulta\n",
    "    for x_query, y_query in zip(X_test, y_test):\n",
    "        idx = knn(x_query, X_train, k)\n",
    "        y_selected = np.take(y_train, idx)\n",
    "        precision = precision_at_k(y_selected, y_query, k)\n",
    "        y_precisions[y_query].append(precision)\n",
    "        \n",
    "    # Calcular medias\n",
    "    for y in y_precisions:\n",
    "        y_precisions[y] = np.mean(y_precisions[y])\n",
    "    \n",
    "    return y_precisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a realizar el cálculo y análisis de la precisión@5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business': 84.77611940298507,\n",
       " 'entertainment': 87.27272727272727,\n",
       " 'politics': 90.9090909090909,\n",
       " 'sport': 95.94202898550725,\n",
       " 'tech': 86.92307692307692}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p5 = mean_precisions_per_class(train_preprocessed, y_train, test_preprocessed, y_test, 5)\n",
    "p5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar el análisis y lectura de estos resultados, vamos a dibujarlos en un diagrama de barras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_p5 = pd.DataFrame.from_dict(p5, orient='index', columns=['precision@5'])\n",
    "\n",
    "df_p5[\"target\"] = list(set(y_test))\n",
    "\n",
    "d = df_p5.set_index(\"target\")\n",
    "\n",
    "df_p5.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos unos resultados muy buenos con una precisión muy alta. Los porcentajes de precisión varían entre el 85% y el 95%, aproximadamente. Estos son valores muy buenos.\n",
    "\n",
    "La categoría de deportes es la que mejor precisión tiene con bastante diferencia. Esto se debe a que seguramente se use vocabulario muy específico, ya que será complicado por ejemplo encontrar la palabra _gol_ en el resto de categorías.\n",
    "\n",
    "Las categorías con peor precisión son las de tecnología y negocios, seguramente por lo contrario al caso anterior. Usarán vocabulario más genérico o más compartido entre ellas. Por ejemplo, la palabra _Excel_ podría estar perfectamente en cualquiera de las dos categorías, refiriendose a una fuente de información económica (negocios) o a una actualización del software (tecnología).\n",
    "\n",
    "A pesar de estas pequeños fallos en la precisión, los resultados obtenidos son muy buenos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lH7sldldpzXi"
   },
   "source": [
    "## 3) Representación basada en word-embeddings y tf-idf\n",
    "\n",
    "La segunda vectorización que vamos a usar representará los mensajes usando usando word-embeddings usando como pesos la frecuencia de aparición de cada palabra. Al igual que en el apartado anterior, usaremos monogramas y las _stop words_ que vienen configuradas por defecto para el inglés. Recuerda usar como vocabulario para vectorizar el vocabulario del fichero con las word-embeddings.\n",
    "\n",
    "Aplica la vectorización a los conjuntos de mensajes de entrenamiento y test.\n",
    "\n",
    "Calcula la precisión@5 de cada una de las clases usando como consultas los documentos de la partición de test y la similitud del coseno. Vamos a considerar que un documento recuperado es relevante cuando pertenezca a la misma clase que la consulta.\n",
    "\n",
    "Dibuja los resultados en un diagrama de barras y compara los resultados con los del apartado anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-J6GYut4DGu"
   },
   "source": [
    "## 4) Análisis de errores\n",
    "\n",
    "Vamos a investigar los resultados para entender mejor dónde están fallando los procesos de recuperación. Sigue los siguientes pasos.\n",
    "\n",
    "\n",
    "1. Identifica la categoría de noticias donde la precisión media haya mejorado más al incorporar word-embeddings\n",
    "2. Para dicha categoría, identifica la consulta donde la precisión haya mejorado más al usar word-embeddings\n",
    "3. Muestra el texto original de la consulta y los términos que aparecen en las dos vectorizaciones tf-idf que usamos (recuerda que usamos diccionarios distintos para las vectorizaciones bolsa de palabras y word-embeddings).\n",
    "4. Identifica las noticias recuperadas para dicha consulta para las dos aproximaciones y sus categorías (TF-IDF puro y con word-embeddings)\n",
    "5. Muestra la intersección de términos entre la consulta y la primera noticia mal recuperada usando TF-IDF puro.\n",
    "6. Muestra la intersección de términos entre la consulta y la última noticia bien recuperada usando word-embeddings.\n",
    "7. A la luz de todo lo anterior, razona sobre por qué crees que el TF-IDF no fue capaz de clasificar bien la noticia y el word-embedding sí.\n",
    "\n",
    "\n",
    "Puedes usar el código que calcula la intersección de términos que ponemos a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RUat8DCRLYs1"
   },
   "outputs": [],
   "source": [
    "def terms_in_message(feature_names,vector_data,index):\n",
    "    '''\n",
    "    Devuelve un conjunto los términos presentes en un mensaje representado como bolsa de palabras.\n",
    "    \n",
    "    - feature_names: terminos usados para vectorizar\n",
    "    - vector_data: matriz (dispersa) de mensaje vectorizados\n",
    "    - index: posición del mensaje a mostrar\n",
    "    '''\n",
    "    mensaje=vector_data[index,:]>0\n",
    "    terminos_presentes = ma.array(feature_names, mask = ~(mensaje[0].toarray()))\n",
    "\n",
    "    return set(terminos_presentes.compressed())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solución:"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "P2_recuperacion_informacion_2122_enunciado.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
