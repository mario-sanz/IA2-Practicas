{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "israeli-category",
   "metadata": {
    "id": "israeli-category"
   },
   "source": [
    "# Práctica 1: Aprendizaje automático\n",
    "\n",
    "__Fecha de entrega: 13 de marzo de 2022__\n",
    "\n",
    "El objetivo de esta práctica es aplicar los distintos algoritmos de aprendizaje automático disponibles en la scikit-learn [sklearn](https://scikit-learn.org/stable/) sobre varios conjuntos de datos y aprender a interpretar los resultados obtenidos. La práctica consta de 3 notebooks que se entregarán simultáneamente en la tarea de entrega habilitada en el Campus  Virtual.\n",
    "\n",
    "Lo más importante en esta práctica no es el código Python, sino el análisis de los datos y modelos que construyas y las explicaciones razonadas de cada una de las decisiones que tomes. __No se valorarán trozos de código o gráficas sin ningún tipo de contexto o explicación__.\n",
    "\n",
    "Finalmente, recuerda establecer el parámetro `random_state` en todas las funciones que tomen decisiones aleatorias para que los resultados sean reproducibles (los resultados no varíen entre ejecuciones)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-samba",
   "metadata": {
    "id": "curious-samba"
   },
   "source": [
    "# Apartado 1: Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-little",
   "metadata": {
    "id": "flexible-little"
   },
   "source": [
    "__Número de grupo: 15__\n",
    "\n",
    "__Nombres de los estudiantes: Javier Sande Ríos y Mario Sanz Guerrero__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-roberts",
   "metadata": {
    "id": "entertaining-roberts"
   },
   "source": [
    "## 1) Carga del conjunto de datos\n",
    "\n",
    "Crea un dataframe a partir del fichero `prestamos.csv` que se proporciona junto con la práctica. \n",
    "\n",
    "El conjunto de datos contiene por cada fila los datos de un préstamo que fue concedido por una empresa de crédito p2p. Las variables que caracterizan el préstamo son las siguientes:\n",
    "  - `loan_amnt` es la cantidad de dinero solicitada en dólares\n",
    "  - `purpose` es el propósito para el que se solicitó el préstamo\n",
    "  - `revenue` son los ingresos anuales en dólares de la persona que solicitó el préstamos\n",
    "  - `dti_n` es el porcentaje de endeudamiento sobre los ingresos anuales de la persona que solicitó el préstamo\n",
    "  - `fico_n` se trata de un indicador de solvencia de la persona que solicitó el préstamo. A mayor puntuación, mayor solvencia, y además se cuenta con estos rangos orientativoss:\n",
    "    - 300-550: Pobre\n",
    "    - 550-620: Subprime (alto riesgo)\n",
    "    - 620-680: Crédito aceptable\n",
    "    - 680-740: Buen crédito\n",
    "    - 740-850: Excelente crédito\n",
    "\n",
    "  -`home_ownership_n` es una variable categórica que indica la situación de vivienda en la que vive la persona solicitante\n",
    "    - `OWN` es en propiedad\n",
    "    - `MORTAGAGE` indica que está hipotecada\n",
    "    - `RENT` indica que vive en alquiler\n",
    "    - `OTHER` es una categoría que agrega otras posibilidades\n",
    "\n",
    "- `emp_length` es una variable ordinal, no es estrictamente numérica, ya que el valor 0 denota que no consta información, los valores entre 1 y 10 indican una permanencia inferior a X años, y el valor 11 indica una permanencia superior a 10 años.\n",
    "- `Default` es la variable que usaremos como **variable objetivo** del conjunto de datos e indica si la persona incumplió (incurrió en *default*) o no el préstamo.\n",
    "\n",
    "\n",
    "Como pandas no tiene forma de saber que las variables `home_ownership_n`, `emp_length` y `Default` son en realidad categóricas, debes indicárselo tú."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-natural",
   "metadata": {
    "id": "convinced-natural"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-basket",
   "metadata": {
    "id": "gorgeous-basket"
   },
   "source": [
    "## 2) Análisis de los datos\n",
    "\n",
    "### 2.1) Numéricos\n",
    "\n",
    "Analiza razonadamente las distribuciones de cada una de las variables numéricas (medias, desviaciones típicas, rangos, ...) y las principales relaciones entre pares de variables (diagrama de dispersión, coeficientes de correlación, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-spanking",
   "metadata": {
    "id": "compound-spanking"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "isW6NIbvhrOY",
   "metadata": {
    "id": "isW6NIbvhrOY"
   },
   "source": [
    "\n",
    "### 2.2) Categóricos\n",
    "\n",
    "Analiza razonadamente las distribuciones de los valores de las variables categóricas incluyendo un diagrama de frecuencias y comentando lo más destacable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-pontiac",
   "metadata": {
    "id": "regional-pontiac"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ranking-mainstream",
   "metadata": {
    "id": "ranking-mainstream"
   },
   "source": [
    "## 3) Preprocesar los datos\n",
    "\n",
    "Para el clustering vamos a trabajar solamente con las variables verdaderamente numéricas. Crea un nuevo dataframe que sólo contenga las variables `loan_amnt`, `revenue`, `dti_n` y `fico_n`.\n",
    "\n",
    "Teniendo en cuenta que vamos a utilizar el algoritmo k-Means para encontrar grupos de préstamos similares, explica razonadamente si es necesario o no cambiar la escalas de los datos y si a priori es mejor reescalarlos (MinMaxScaler) o estandarizarlos (StandarScaler).\n",
    "\n",
    "Si decides preprocesarlos, accede al array interno del dataframe y crea un nuevo array con los datos escalados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-baker",
   "metadata": {
    "id": "designing-baker"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-volume",
   "metadata": {
    "id": "appreciated-volume"
   },
   "source": [
    "## 4) Encontrar el número óptimo de clusters\n",
    "\n",
    "Decide razonadamente el número óptimo de clusters en el rango 2..10. Ten en cuenta que para interpretar los datos no nos interesa tampoco tener un número excesivo de clusters. Para hacerlo calcula y pinta el diagrama del codo, el índice davies_boulding y el coeficiente silhouette en función del número de clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-dispatch",
   "metadata": {
    "id": "substantial-dispatch"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "limited-temple",
   "metadata": {
    "id": "limited-temple"
   },
   "source": [
    "## 5) Descripción de los clusters\n",
    "\n",
    "Describe los clusters que has obtenido en el apartado anterior. Si te han salido más de 3, elige 3 de ellos que sean bastante diferentes entre sí. \n",
    "\n",
    "Para hacerlo estudia sus descriptores estadísticos y dales un sentido dentro del contexto del problema. ¿Qué perfil de préstamos quedan en cada cluster? Según dicho perfil, ¿qué cluster te parece que tendrá una mayor tasa de \"default\"? Corrobóralo calculando para cada cluster la proporción de préstamos que acabaron en \"default\".\n",
    "\n",
    "Pinta el diagrama de dispersión en función de cada par de variables usando colores diferentes para cada cluster. ¿Qué clusters se separan mejor y en función de qué variables? ¿y cuáles se confunden más?\n",
    "\n",
    "__Cuidado__: para poder interpretar correctamente los datos necesitas que estén en su escala original. Si decidiste escalar los datos, deberás ejecutar k-Means con los datos escalados pero asignar las etiquetas de clusters al conjunto de datos inicial. En este caso es muy sencillo porque el algoritmo no cambia el orden de los datos así que puedes crear directamente una nueva columna en el dataframe original con esas etiquetas. Puede que aparezca un SettingWithCopyWarning por asignar una nueva columna en un dataframe que es una vista de otro dataframe. Puedes ignorar este aviso o puedes hacer una copia del dataframe con `copy` para que no comparta memoria con el otro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-ambassador",
   "metadata": {
    "id": "grand-ambassador"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "P1_clustering_enunciado.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
